{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Practicing NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Define a new Python *list*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us practice defining a new list in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [0,0,1,2,3,3,4.5,7.6]\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. (Two ways to) define a *range*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One type of list is a range of (e.g., integer) numbers. Ranges are useful for iterating over in a loop -- that is, to assign some variable to take on each value in this lest sequentially. (For example, `i=1`, then `i=2`, then `i=3`, etc., until `i=100`.) <br>\n",
    "\n",
    "Let's create an evenly spaced array of integers ranging from 0 to 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, the basic python way:\n",
    "my_range = range(0,12)\n",
    "my_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now the numpy way:\n",
    "my_range_np = np.arange(12)\n",
    "my_range_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the first method returns a special 'range' object, while the latter returns an object of type 'numpy array'. If we convert both to lists, they will be the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(my_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(my_range_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. List comprehension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the task of replacing each value in a list with its square. The traditional way of performing te same transformation on every element of a list is via a *for* loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_range_np = np.arange(12)\n",
    "\n",
    "for i in range(0, len(my_range_np)):\n",
    "    my_range_np[i] = my_range_np[i]**2 #square each element\n",
    "print(my_range_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked. However, there is a better, more 'Pythonic' way to do it. <br>\n",
    "\n",
    "*List comprehension* is one of the most elegant functionalities native to Python, and is beloved by programmers like you. It offers a concise way of applying a particular transformation to every element in a list. <br>\n",
    "\n",
    "Using list comprehension syntax, we can write a single, easily interpretable line that does the same transformation without using ranges, nor do we have to introduce an iterating index variable `i`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_range_np = np.arange(12)\n",
    "\n",
    "my_range_np = [x**2 for x in my_range_np]\n",
    "my_range_np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Creating a one-dimensional NumPy *array*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explicitly create a one-dimensional numpy array (as opposed to a list):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([1, 2, 3, 4])\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e.  Retrieving the dimensions of data structure:  len() and np.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we go about creating a variable that contains the length of our array `arr` ?<br>\n",
    "We could use the python function ```len()```... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_length = len(arr)\n",
    "arr_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or use the numpy method ```np.shape```, saving only the first of the two values that it returns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_length = np.shape(arr)[0]\n",
    "arr_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Tip: try removing the slice indicator `[0]` and see how the printout changes. Notice that there appears to be an empty 'slot' for another number in the returned value pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Creating a uniform (same value in every position) array: np.ones()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use ```np.ones``` to create an array of a pre-specified length that contains the value '1' in each position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 55\n",
    "np.ones(length, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this method to create an array of any identical values. <br>\n",
    "Let's create an array of length 13, filled with the vlue '7' in every position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7*np.ones(13, dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Creating two-dimensional arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the possibilities of the ```np.array``` method further, let's move on to creating not one- but two-dimensional arrays (aka matrices):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.array([[1,2,3], [4,5,6]])\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy contains useful methods for creating identity matrices of a specified size:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Creating an identity matrix: np.eye()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.eye(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check your intuition: what will be the printout after running this cell?\n",
    "A = np.eye(3)\n",
    "B = 4*np.eye(3)\n",
    "A+B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. A small challenge:  matrix transformation; random matrix generation\n",
    "Using the matrix ```M``` below and the function ```np.tril``` (pull up the documentation by typing ```np.tril?```), create a matrix ```N``` which is identical to ```M``` except in the lower triangle (i.e., all the cells below the diagonal). The lower triangle should be filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tril?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.round(np.random.rand(5,5),2)\n",
    "print(\"M=\\n\", M)\n",
    "\n",
    "# your code here:\n",
    "N = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the code provided above for generating the matrix ```M```, try to figure out how to create a random matrix with 13 rows and 3 columns. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here:\n",
    "M = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j. Indexing arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to call an element of a 2D array by its location (i.e., its row index and column index):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test your intuition: what would you expect this code to return?\n",
    "M[3:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k. Evaluating a Boolean condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real-life data tasks, you will often have to compute the boolean ```(True/False)``` value of some statement, for all entries in a list, or for a matrix column (essentially, a list), or for the entire matrix. <br>\n",
    "In other words, we may want want to formulate a condition -- think of it as a *test* -- and run a computation that returns `True` or `False` depending on whether the test is passed or failed by a particular value in a data structure.\n",
    "\n",
    "For example, our test may be something like \"the value is greater than 0.5\", and we would like to know if this is true or false for each of the values in a list. Here's how to compute a list of values that the condition test takes for each value of a given list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = np.random.rand(1, 20) #first, create the list \n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_greater = g>0.5\n",
    "print(is_greater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the matrix M again so we can glance at it for our next exercise\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What would you expect to see once you run the code below?\n",
    "c_is_greater = M[:,1]>0.5\n",
    "c_is_greater"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L . Numpy functions `np.any`, `np.unique `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use ```np.any``` to determine if there is any entry in column 1 that is smaller than 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_is_smaller = M[:,1]<0.1\n",
    "np.any(c_is_smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small challenge:<br>\n",
    "You have birthday data for a cohort of 100 people all born in 1990.\n",
    "Given the one-dimensional array of birthdays ```random_bdays``` generated below, figure out if there exists a pair of people who share a birthday.<br>\n",
    "( Tip: you may find the function ```np.unique()``` useful. Feel free to read up on it by printing `np.unique?` in a new cell )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this code:\n",
    "random_nums = np.random.choice(365, size = 100)\n",
    "random_bdays = np.datetime64('1990-01-01') + random_nums\n",
    "\n",
    "## your code here:\n",
    "duplicates_exist = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Pandas DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Creating a DataFrame: two (of the many) ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will overview two ways of creating Pandas dataframes from scratch: from a *list of lists*, and from a *dictionary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [['+1', '(929)-000-0000'], ['+34', '(917)-000-0000'], ['+7', '(470)-000-0000']]\n",
    "df = pd.DataFrame(my_list, columns = ['country_code', 'phone'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict = {'country_code': ['+1', '+34', '+7'], 'phone':['(929)-000-0000', '(917)-000-0000', '(470)-000-0000']}\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Adding a column to a DataFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we add a new column of values to the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['grade']= ['A','B','A']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Sorting the dataframe by values in a specific column: `Pandas.df.sort_values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['grade'], axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real life settings, you will often need to combine separate sets of related data.<br>\n",
    "To illustrate, let's create a second dataframe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. Combining multiple dataframes: `Pandas.concat` and `Pandas.merge`. Renaming the columns: `df.rename()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict2 = {'country': ['+32', '+81', '+11'], 'grade':['B', 'B+', 'A'], 'phone':['(874)-444-0000', '(313)-003-1000', '(990)-006-0660']}\n",
    "df2 = pd.DataFrame(my_dict2)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Pandas ```pd.concat``` method to append the second dataframe to the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One immediate problem with this result is that the index has repeated values. This defeats the purpose of an index, and ought to be fixed. Let's try the concatenation again, this time adding `reset_index()` method to produce correct results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df,df2]).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! <br>\n",
    "This result is valid, but it contains redundancy caused by different spelling of the country code column in the two dataframes. This can be easily fixed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.rename(columns={'country':'country_code'})\n",
    "\n",
    "pd.concat([df,df2]) # aha!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if our task was to merge ```df2``` with yet another dataset -- one that contains additional unique columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict3 = {'country_code': ['+32', '+44', '+11'], 'phone':['(874)-444-0000', '(575)-755-1000', '(990)-006-0660'], 'grade':['B', 'B+', 'A'], 'n_credits': [12, 3, 9]}\n",
    "df3 = pd.DataFrame(my_dict3)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to consult the definition of the Pandas ```merge``` method to better undertsand the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.merge(df3, on = 'phone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Loading a dataset: `Pandas.read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now well equipped to deal with a real dataset!<br>\n",
    "\n",
    "\n",
    "For the next few exercises, our dataset will contain information about New York City listings on the Airbnb platform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "filename = os.path.join(os.getcwd(), \"labs_data\", \"airbnb_lab1.csv.gz\") # path to file and file name\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get a peek at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot of columns, and the layout is a little difficult to read. <br>\n",
    "Let us retrieve just the list of column names, so we can read it and get a feeling for what kind of information is presented in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f. Get column names: `df.columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the column names mean? Some of them are less intitively interpretable than others. <br>\n",
    "Careful data documentation is indispensable for business analytics. Make sure to consult the documentation that accompanies this open source dataset for a detailed description of the key variable names, what they represent, and how they were generated:  https://docs.google.com/spreadsheets/d/1iWCNJcSutYqpULSQHlNyGInUvHg2BoUGoNRIGa6Szc4/edit#gid=982310896 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Summary statistics of the dataset: `df.describe()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print some general statistics for each one of the data columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>Consider the following business question:<br>\n",
    "What is the average availability (out of 365 days in a year) for the listings in Brooklyn? <br>\n",
    "The answer can be obtained by the use of **filters** on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### h. Filtering the data: `df[ < condition > ]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to filter the entries that are in Brooklyn. To do this, we need to know what is the exact way that Manhattan listings are spelled and entered in the data. Let's print all of th eunique values of the 'neighborhood' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['neighbourhood'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there is a lot of heterogeneity in the way 'neighborhood' values are specified. The values are not standardized. There are overlaps, redundancies, and inconsistencies (e.g., some entries specify ```'Greenpoint, Brooklyn, New York, United States'```, some other ones list `'BROOKLYN, New York, United States',`, yet other ones say `'Williamsburg, Brooklyn, New York, United States'`, etc. In real life, you would have to clean this data and replace these values with standard, identically formated, consistent values. <br>\n",
    "\n",
    "For this data file, however, we are lucky to already have a 'cleansed' version of the neighborhood information based on the latitude and the longitude of every listing location. \n",
    "\n",
    "We will list the unique values of the columns titled 'neighbourhood_cleansed' and 'neighbourhood_group_cleansed']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['neighbourhood_cleansed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['neighbourhood_group_cleansed'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, this last one is what we want! Let's filter out all data entries that pertain to Brooklyn listings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk = data[data['neighbourhood_group_cleansed'] == 'Brooklyn']\n",
    "bk.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Tip: to better understand what happenned above, you are incouraged to insert a new code cell below and copy *just the condition* of the filter that we used on the `data` object above -- that is, everything that we specified inside the brackets for the outermost data[...]. Run the new cell and see what that condition alone evalueates to ---- you should see a series of True/False values. When we pass that series to `data` as a Boolean filter by writing<br> `data[ < our Boolean series > ]`,<br> we tell Pandas to keep the values of `data` only with those indices for which the condition evaluated to `True`. Don't worry! You'll get the hang of this!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Combining values in a column: `np.mean()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we isolated only the relevant entries, it remains to average the value of a particular column that we care about:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(bk['availability_365'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### j. Group data by (categorical) column values: `df.groupby`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question of interest could be:<br>\n",
    "What are the top 5 most reviewed neighborhoods in New York? (By sheer number of reviews, regardless of their quality). <br>\n",
    "We will use the ```.groupby``` method from the Pandas package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhd_reviews = data.groupby('neighbourhood_cleansed')['number_of_reviews'].sum()\n",
    "nbhd_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform a (descending order) sorting on this series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhd_reviews = nbhd_reviews.sort_values(ascending = False)\n",
    "nbhd_reviews.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!<br>\n",
    "While we re at it, what are the least reviewed neighborhoods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbhd_reviews.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result makes it apparent that our dataset is somewhat messy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we could have chained the transformations above into a single command, as in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('neighbourhood_cleansed')['number_of_reviews'].sum().sort_values(ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way we don't store objects that we won't need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: easy histogram plotting with Matplotlib: `plt.hist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final touch, run the cell below to instantly visualize the density of (average!) values of review numbers across all neighbourhoods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "nbhd_reviews.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot suggests that the vast majority of neighborhoods have only very few reviews, with just a handful of outliers (those ranked at the top in our previous computed cell) having the number of reviews upward of 40000. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
